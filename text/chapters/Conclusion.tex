\chapter{Conclusion}

The primary objective of our thesis was to find the best model for supervised text classification of automatic ticket triage in order to achieve the best practical result for a web application requested by a private Czech-based software company. We have concluded that the best classification model is SVM with TF--IDF---achieving accuracy of 57\%, precision of 51\% and recall of 45\% with Firefox dataset---53\%, 53\% and 49\% with Netbeans dataset---and finally 53\%, 59\% and 47\% with the private company dataset. The secondary objective of our thesis was to find out whether the best model can be applied to all projects without optimizing the parameters. Our analysis and evaluation helped us determine that while some classification models do require optimization of the model's parameters for each project, our best model (SVM with TF--IDF) does not suffer this drawback.

Another important objective of our thesis was to find out if there is a difference between open-source and proprietary data. Our analysis of the datasets and evaluation of the models showed that there is a difference especially when comparing the performance of the datasets without filtering developers with little activity as a lot of bug reports in an open-source repository are resolved by one-time users (users that are not actively maintaining the project and fixed only a few bugs).

Future work could extend several aspects of our thesis. We have attempted to discover whether it is auspicious to pay attention to the size of the time window within which the samples form a training dataset had been created. While our results are for the most part inconclusive, it seems plausible that the size of a time window affects the performance of a classification model. Another aspect of our thesis that could be extended is the evaluation process. The measured results exhibit quite a lot of variance and it would therefore be more accurate to evaluate each model several times in order to compute the mean value possibly with confidence intervals. The set of used metrics could possibly be extended as well with metrics like AUC and ROC.

Machine learning and text classification are still quite young disciplines and only our recent technologies provided us with enough computational power to drive the research in these fields of study further. Our results, while satisfactory in the context of the related work, can almost certainly be improved with different, possibly yet undiscovered, techniques and methods---because if a human can predict an assingee for a bug report with higher accuracy than our classification model (which they almost certainly can), so can a computer.
